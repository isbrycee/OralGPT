# ğŸ§  VLMEvalKit ä½¿ç”¨æŒ‡å—

> æœ¬é¡¹ç›®ç”¨äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (VLM) çš„è‡ªåŠ¨åŒ–è¯„ä¼°ä¸æµ‹è¯•ã€‚  
> è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆç¯å¢ƒé…ç½®ä¸è¿è¡Œã€‚

---

## ğŸš€ 1. ç¯å¢ƒé…ç½®

### ğŸ§© åˆ›å»º `.env` æ–‡ä»¶

åœ¨ `$VLMEvalKit/.env` å¤„åˆ›å»ºå¹¶å¡«å†™ä»¥ä¸‹å†…å®¹ï¼š
bash
OpenAI API
OPENAI_API_KEY=
OPENAI_API_BASE=
> ğŸ’¡ `.env` æ–‡ä»¶ç”¨äºä¿å­˜ç§å¯†çš„ API é…ç½®ï¼Œè¯· **ä¸è¦ä¸Šä¼ åˆ°å…¬å…±ä»“åº“**ï¼

---

## âš™ï¸ 2. é…ç½®æ¨¡å‹ä¿¡æ¯

æ‰“å¼€å¹¶ç¼–è¾‘ `vlmeval/config.py` æ–‡ä»¶ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
python
æ³¨æ„ï¼šVLMEvalKit ä½¿ç”¨çš„æ˜¯ requests.post æ–¹å¼ï¼Œ
å› æ­¤éœ€è¦ä½¿ç”¨ post ç‰ˆæœ¬çš„ api_base
from functools import partial
from vlmeval.vlm import GPT4V
test_models = {
"gpt-4.1-nano": partial(
GPT4V,
model="gpt-4.1-nano",
api_base="https://www.dmxapi.cn/v1/chat/completions",
temperature=1,
img_size=-1,
img_detail="high",
retry=10,
verbose=True,
),
}
---

## ğŸ” 3. æ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦æˆåŠŸ

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯æ¨¡å‹åŠ è½½æ˜¯å¦æˆåŠŸï¼š
bash
vlmutil check gpt-4.1-nano
> âœ… è‹¥è¿”å›æ¨¡å‹å¯ç”¨æˆ–æ­£å¸¸å“åº”ç»“æœï¼Œå³ä»£è¡¨é…ç½®æˆåŠŸã€‚

---

## âš’ï¸ 4. é…ç½®è¿è¡Œå‚æ•°

ç¼–è¾‘æˆ–æ–°å»º `run_config.json` æ–‡ä»¶ï¼Œé…ç½®å†…å®¹åŒ…æ‹¬ï¼š

- æµ‹è¯•æ¨¡å‹ï¼ˆä¾‹å¦‚ä¸Šé¢çš„ `gpt-4.1-nano`ï¼‰
- æµ‹è¯•æ•°æ®é›†è·¯å¾„
- è¯„ä¼°æ–¹å¼åŠ Judgerï¼ˆå¦‚éœ€ï¼‰

ç¤ºä¾‹ç»“æ„ï¼š
json
{
"models": ["gpt-4.1-nano"],
"datasets": ["MMOral-Omni-Bench"],
"judger": "gpt-4o-mini",
"other_args": {}
}
---

## ğŸ§­ 5. å¯åŠ¨è¯„ä¼°è„šæœ¬
bash
python run.py --config run_config.json \
--mode all \
--api-nproc 4 \
--work-dir '.' \
--verbose
> ğŸ“Œ å¦‚æœæƒ³é‡å¤ä½¿ç”¨å·²æœ‰ç»“æœï¼Œå¯åŠ ä¸Š: `--reuse`

### ğŸ’¬ å‚æ•°è¯´æ˜ï¼š

| å‚æ•° | è¯´æ˜ |
|------|------|
| `--mode all` | æ‰§è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹ |
| `--api-nproc` | è®¾ç½®å¹¶è¡Œè¯·æ±‚æ•° |
| `--work-dir` | æŒ‡å®šå·¥ä½œç›®å½• |
| `--verbose` | æ˜¾ç¤ºè¯¦ç»†æ—¥å¿— |

---

## âš ï¸ 6. ä½¿ç”¨æ³¨æ„äº‹é¡¹

### ğŸ—‚ï¸ ä¿®æ”¹æ•°æ®é›†æ–‡ä»¶

å¦‚éœ€ä¿®æ”¹æ•°æ®é›†æ–‡ä»¶ï¼Œéœ€åŒæ­¥æ›´æ–°ä»¥ä¸‹å†…å®¹ï¼š

- æ–‡ä»¶ï¼š`MMOral-Omni-Bench.tsv`
- å¯¹åº”çš„ MD5 å€¼é…ç½®ä½äºï¼š  
  `$VLMEvalKit/vlmeval/dataset/image_vqa.py`  
  ç¬¬ **1690** è¡Œ ä¸ ç¬¬ **1694** è¡Œ

#### MD5 è·å–æ–¹å¼ï¼š
bash
md5sum file_path
---

### ğŸ§¹ å¯é€‰ï¼šæ¨¡å‹è¾“å‡ºåå¤„ç†

å¦‚éœ€å¯¹æ¨¡å‹è¾“å‡ºç»“æœè¿›è¡Œåå¤„ç†ï¼ˆä¾‹å¦‚å»é™¤ Think éƒ¨åˆ†ï¼Œä»…ä¿ç•™æœ€ç»ˆç­”æ¡ˆï¼‰ï¼Œè¯·ç¼–è¾‘æ–‡ä»¶ï¼š

`$VLMEvalKit/vlmeval/inference.py`

å®šä½åˆ°ç¬¬ **244** è¡Œå¹¶ä¿®æ”¹ç›¸åº”é€»è¾‘å³å¯ã€‚

---

## ğŸ’¬ 7. åé¦ˆä¸è´¡çŒ®

è‹¥ä½ åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜æˆ–æœ‰ä¼˜åŒ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼åé¦ˆï¼š

- ğŸ› **æäº¤ Issue**
- ğŸ’¡ **æäº¤ Pull Request**
- â­ **ç»™ä»“åº“ç‚¹ä¸ª Star æ”¯æŒä¸€ä¸‹ï¼**

## ğŸ–Šï¸ Citation

If you find this work helpful, please consider to **starğŸŒŸ** this repo. Thanks for your support!

If you use VLMEvalKit in your research or wish to refer to published OpenSource evaluation results, please use the following BibTeX entry and the BibTex entry corresponding to the specific VLM / benchmark you used.

```bib
@article{oralgpt2025,
  title={Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis},
  author={Hao, Jing and Fan, Yuxuan and Sun, Yanpeng and Guo, Kaixin and Lin, Lizhuo and Yang, Jinrong and Ai, Qi Yong H and Wong, Lun M and Tang, Hao and Hung, Kuo Feng},
  journal={arXiv preprint arXiv:2509.09254},
  year={2025}
}
```

<p align="right"><a href="#top">ğŸ”Back to top</a></p>
